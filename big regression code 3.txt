Update the installed packages first
update.packages(ask = FALSE, repos = 'http://cran.rstudio.com/')
##  Many thanks for the code taken from Ioanis Kosmidis, UCL from a course
## on Big data regression
# Install the packages for this tutorial
PFpackages <- c('biglm', 'ffbase', 'ggplot2', 'sgd')
install.packages(PFpackages, repos = 'http://cran.rstudio.com/')
# ffbase Provides support for data.frame like objects that connect to
# files stored out of memory
require(ffbase)
# biglm implements a bounded-memory fitter for glms
require(biglm)
# ggplot2 is for flexible plotting
require(ggplot2)
# sgd is for stochastic gradient descent methods
require(sgd)


HiggsDir <- paste0(mydir, "/", "HIGGS"); cdir <- getwd()
HiggsURL <- "https://goo.gl/3j9Jpr"
## Download the data: this will download 2.6 GB in HiggsDir. If this does
## not work for you, then copy and paste the link to a browser.
setwd(HiggsDir); download.file(dataURL, "HIGGSdata.csv.gz")
## decompress: this takes a while and will create an 8.0 GB csv file. For
## linux/Mac OSX systems the following command should work out of the box.
## For windows install 7zip (http://www.7-zip.org) and extract manually.
system("gunzip -kdv HIGGSdata.csv.gz")
## Read the HIGGS data in a ffdf object: Had to wait ~ 15 minutes
## on my laptop for the following to complete
varnames <- c("signal", paste0("feature", 1:21), paste0("HLfeature",1:7))
Higgs_ffdf <- read.csv.ffdf(file = "HIGGSdata.csv",
header = FALSE,
VERBOSE = TRUE,
next.rows = 5e+05,
col.names = varnames,
colClasses = rep("double", length(varnames)))
## set test variable (0 if observation is for training, 1 if for test)
Higgs_ffdf$test <- c(ff(0, 10500000), ff(1, 500000))
## Write ffdf object to the disk and go back to the working directory
save.ffdf(Higgs_ffdf, dir = "./HIGGSffdf", overwrite = TRUE); setwd(cdir)


AirlinesDir <- paste0(mydir, "/", "airlines"); cdir <- getwd()
setwd(AirlinesDir)
years <- 1987:2008 ## Years to download
## Download and decompress the data for all years: this takes a while and
## will require 13.7 GB. If this does not work for you then download
## manually from http://stat-computing.org/dataexpo/2009/the-data.html.
## For linux/Mac OSX systems the following command should work out of
## the box. For windows install 7zip (http://www.7-zip.org) and extract
## manually.
for (year in years) { filename <- paste0(year, ".csv.bz2")
dataurl <- paste0("http://stat-computing.org/dataexpo/2009/",
filename)
download.file(dataurl, filename)
system(paste("bzip2 -kdv", filename))
}setwd(cdir)

AirlinesDir <- paste0(mydir, "/", "airlines")
load.ffdf(paste0(AirlinesDir, "/", "airlinesffdf"))
## Let's get only the data for 2007
year <- 2007
AirlinesC <- subset(Airlines, Year == year)
## Construct variables Weekend and MonthF
AirlinesC$Weekend <- as.character(AirlinesC$DayOfWeek > 4)
AirlinesC$MonthF <- as.character(AirlinesC$Month)
## Still pretty big subset
dim(AirlinesC)
## Not very inspiring but let's do a two-way ANOVA of length of
## departure delays in 2007 for the levels of MonthF and Weekend
## Fit the model with main effects for weekend and month
mMain <- bigglm(DepDelay ~ Weekend + MonthF, data = AirlinesC,
chunksize = 5*1e+05, family = gaussian())
## ## Fit the model with interaction
mInt <- bigglm(DepDelay ~ Weekend*MonthF, data = AirlinesC,
chunksize = 5*1e+05, family = gaussian())
## Extract residual sums of squares
c("Main effects" = deviance(mMain), "Interaction" = deviance(mInt))
## Really not much improvement in RSS by including the interactions
## Notes:
## - These simple fits are taking up all my laptop's memory if I use glm!
## - Model comparison is not a good idea here as the length of departure
## delays must have a rather skew distribution

setwd(AirlinesDir)
varnames <- c("Year", "Month", "DayofMonth", "DayOfWeek", "DepTime",
"CRSDepTime", "ArrTime", "CRSArrTime", "UniqueCarrier",
"FlightNum", "TailNum", "ActualElapsedTime",
"CRSElapsedTime", "AirTime", "ArrDelay", "DepDelay",
"Origin", "Dest", "Distance", "TaxiIn", "TaxiOut",
"Cancelled", "CancellationCode", "Diverted", "CarrierDelay",
"WeatherDelay", "NASDelay", "SecurityDelay", "LateAircraftDelay")
colclasses <- c(rep("double", 8), "factor", "double", "factor",
rep("double", 5), rep("factor", 2), rep("double", 11))
Airlines <- read.csv.ffdf(file = paste0(AirlinesDir, "/", years[1], ".csv"),
header = TRUE, next.rows = 5e+05,
col.names = varnames, colClasses = colclasses,
VERBOSE = TRUE)
for (year in years[-1]) { filepath <- paste0(AirlinesDir, "/", year, ".csv")
yeardata <- read.csv.ffdf(file = filepath,
header = TRUE, next.rows = 5e+05,
col.names = varnames, VERBOSE = TRUE,
colClasses = if (year < 2003) colclasses else NA)
Airlines <- ffdfappend(Airlines, yeardata); delete(yeardata)
}save.ffdf(Airlines, dir = paste0(AirlinesDir, "/", "airlinesffdf"),
overwrite = TRUE)
setwd(cdir)
## Not very inspiring but let's do a two-way ANOVA of length of
## departure delays in 2007 for the levels of MonthF and Weekend
## Fit the model with main effects for weekend and month
mMain <- bigglm(DepDelay ~ Weekend + MonthF, data = AirlinesC,
chunksize = 5*1e+05, family = gaussian())
## ## Fit the model with interaction
mInt <- bigglm(DepDelay ~ Weekend*MonthF, data = AirlinesC,
chunksize = 5*1e+05, family = gaussian())
## Extract residual sums of squares
c("Main effects" = deviance(mMain), "Interaction" = deviance(mInt))
## Really not much improvement in RSS by including the interactions
## Notes:
## - These simple fits are taking up all my laptop's memory if I use glm!
## - Model comparison is not a good idea here as the length of departure
## delays must have a rather skew distribution
